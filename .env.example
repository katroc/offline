### MCP Server
MCP_PORT=8787
MCP_HOST=127.0.0.1

### Document Sources Configuration
# Confluence (required for real RAG - leave empty to use mock data)
CONFLUENCE_BASE_URL=https://confluence.local
CONFLUENCE_USERNAME=service-account
CONFLUENCE_API_TOKEN=your-api-token-here

### LLM Configuration (Ollama or OpenAI-compatible)
# Set this to enable LLM answers; leave empty to use stubbed answers
LLM_BASE_URL=http://127.0.0.1:11434
LLM_CHAT_MODEL=llama3.1:8b
LLM_EMBED_MODEL=nomic-embed-text

### Request timeouts
REQUEST_TIMEOUT_MS=15000

### Vector Database
LANCEDB_PATH=./data/lancedb
CHUNK_TTL_DAYS=7
MIN_VECTOR_RESULTS=3
ADAPTIVE_THRESHOLD=false
# Optional lexical floor for vector results (0..1)
MIN_KEYWORD_SCORE=0.0

### Logging
LOG_LEVEL=info
